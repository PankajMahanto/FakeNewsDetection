
# ğŸ“° Fake News Detector (BERT + Streamlit)

A real-time fake news detection web application built using a fine-tuned BERT model with an elegant Streamlit interface. The system supports manual input and URL-based article analysis with multilingual support and clean visual feedback.


The Fake News Detection Web Application is a locally deployed tool that uses traditional machine learning algorithms like Logistic Regression and Random Forest to classify news articles as real or fake. It offers a simple web interface for real-time predictions, aiming to combat misinformation and promote media awareness.

---
## ğŸ§  Model Architecture: BERT-Powered Fake News Detection System
![Working](./test-output/Fnd.png)
---
## ğŸ§ª Screenshots
![Home](./test-output/1.png)
--
![Manual text](./test-output/2.png)
--
![Results](./test-output/3.png)
--
![URL](./test-output/4.png)
--
![Results_url](./test-output/5.png)
## ğŸ” Features

- ğŸ§  BERT-based classification of news articles as **Fake** or **Real**
- ğŸŒ URL scraping using `newspaper3k` and auto language detection
- âœ¨ Real-time feedback with model-wise comparison: Logistic Regression, Random Forest, SVM, Naive Bayes, and BERT
- ğŸ“Š Dynamic confidence bars (green = Real, red = Fake)
- ğŸŒ Auto-translation for non-English news using Google Translate
- ğŸ“± Streamlit-powered UI with dark mode and modern UX

---

## ğŸ› ï¸ Tech Stack

- **Frontend**: Streamlit
- **ML Models**: 
  - Logistic Regression
  - Random Forest
  - Naive Bayes
  - SVM
  - BERT (`transformers` by HuggingFace)
- **Vectorizers**: `TfidfVectorizer`, `CountVectorizer`
- **Tools**: `joblib`, `torch`, `langdetect`, `deep-translator`, `newspaper3k`

---

## ğŸš€ How to Run

### 1. Clone the Repository

```bash
git clone https://github.com/PankajMahanto/FakeNewsDetection.git
cd FakeNewsDetection
```
### 2. Create a Virtual Environment (Optional but Recommended)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

```

### 3. Install Requirements
```
bash
pip install -r requirements.txt
```
### 4. Run the App
```
bash
streamlit run app.py
```

## ğŸ“ Project Structure
```
bash

|â€”â€” .gitattributes
|â€”â€” app.ipynb
|â€”â€” app.py
|â€”â€” app_rf.ipynb
|â€”â€” bert_fakenews
|    |â€”â€” config.json
|    |â€”â€” model.safetensors
|    |â€”â€” special_tokens_map.json
|    |â€”â€” tokenizer.json
|    |â€”â€” tokenizer_config.json
|    |â€”â€” vocab.txt
|â€”â€” bert_fakenews_vs.ipynb
|â€”â€” copy-app.py
|â€”â€” Datasets
|    |â€”â€” Fake.csv
|    |â€”â€” True.csv
|â€”â€” Datasets.zip
|â€”â€” lr_model.jb
|â€”â€” model.jb
|â€”â€” model_load.ipynb
|â€”â€” nb_model.jb
|â€”â€” r.md
|â€”â€” requirements.txt
|â€”â€” rf_model.jb
|â€”â€” rf_model.zip
|â€”â€” svm_model.jb
|â€”â€” tfidf_vectorizer.jb
|â€”â€” train_bert.py
|â€”â€” train_bert_news.ipynb
|â€”â€” Train_nb.ipynb
|â€”â€” train_svm.ipynb
|â€”â€” vectorizer.jb
|â€”â€” vectorizer_nb.jb
|â€”â€” vectorizer_rf.jb
|â€”â€” visualization_of_project.ipynb
```
## Code Details
### Tested Platform
- software
  ```
  OS: Debian unstable (May 2021), Ubuntu LTS
  Python: 3.8.5 (anaconda)
  PyTorch: 1.7.1, 1.8.1
  ```
- hardware
  ```
  CPU: Intel Xeon 6226R / Normal CPU work
  GPU: No Needed (24GB)
  RAM: At least 8GB
  ```

## ğŸ‘¤ Author
Made with â¤ï¸ by  [Pankaj Mahanta](https://github.com/PankajMahanto/)